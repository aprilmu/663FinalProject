{
 "metadata": {
  "name": "",
  "signature": "sha256:bf4e9c7ae8550eaacad85e6cc007e9aa1371929a37852e5c5a58213fe73fd0e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "K-means Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initialization(data,k):\n",
      "    \"\"\"Return the initial set of cluster centers\"\"\"\n",
      "    #Generate k random indices between 0 and the number of rows in the dataset\n",
      "    centers_index = np.random.choice(range(data.shape[0]), k, replace=False)\n",
      "    return data[centers_index, :]\n",
      "\n",
      "def kmeans(data,k):\n",
      "    #Generate initial cluster centers\n",
      "    centers = initialization(data,k)\n",
      "    print('Initial Centers:', centers)\n",
      "\n",
      "    converge = False\n",
      "\n",
      "    phi = []\n",
      "    iterations = 0\n",
      "    while (not converge) and (iterations < 1000):\n",
      "        #Find the Euclidean distance between a center and a data point\n",
      "        data2 = data[:, np.newaxis, :]\n",
      "        d2 = (data2 - centers) ** 2\n",
      "        #Calculate the total distance to each center for each data point.\n",
      "        distance = np.sum(d2, axis=2)\n",
      "\n",
      "        #Find out which cluster each data point belongs to.\n",
      "        min_index = np.zeros(distance.shape)\n",
      "        min_index[range(distance.shape[0]), np.argmin(distance, axis=1)] = 1\n",
      "\n",
      "        #Calculate phi \n",
      "        phi_val = np.sum(distance[min_location == True])\n",
      "        phi.append(phi_val)\n",
      "\n",
      "        #Calculate the new centers\n",
      "        new_centers = np.empty(centers.shape)\n",
      "        for i in range(0, k):\n",
      "            if data[min_index[:, i] == True,:].shape[0] == 0:\n",
      "                new_centers[i] = centers[i]\n",
      "            else:\n",
      "                new_centers[i] = np.mean(data[min_index[:, i] == True, :], axis=0)\n",
      "\n",
      "        #Compare old centers with new centers to see if the algorithm has converged\n",
      "        if compare_centers(centers, new_centers):\n",
      "            converge = True\n",
      "        else:\n",
      "            centers = new_centers\n",
      "\n",
      "        iterations += 1\n",
      "\n",
      "    print ('Required ', iterations, ' iterations to converge.')\n",
      "    return (iterations, phi, centers, min_index)\n",
      "\n",
      "def compare_centers(centers, new_centers, tol=-1):\n",
      "    if tol == -1:\n",
      "        return np.array_equal(centers, new_centers)\n",
      "    else:\n",
      "        diff = np.sum((new_centers - centers)**2, axis=1)\n",
      "        if np.max(diff) <= tol:\n",
      "            return True\n",
      "        else:\n",
      "            return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmeans(data,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Initial Centers:', array([[-0.5951, -0.0921],\n",
        "       [ 7.6976,  8.3106],\n",
        "       [ 3.778 ,  5.7559]]))\n",
        "('Required ', 3, ' iterations to converge.')\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "(3, [300.4844, 107.1008, 92.1328], array([[ -0.032 ,   0.7432],\n",
        "        [  9.7711,  10.8707],\n",
        "        [  4.7455,   5.9668]]), array([[ 0.,  1.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 1.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 0.,  0.,  1.],\n",
        "        [ 0.,  1.,  0.],\n",
        "        [ 1.,  0.,  0.]]))"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "K-means++ Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial import distance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_data(n):\n",
      "    mean0 = [0, 1]\n",
      "    cov0 = [[1, 0.5], [0.5, 1]]\n",
      "    data0 = np.random.multivariate_normal(mean0, cov0, n)\n",
      "    data0 = np.hstack((data0, np.ones((data0.shape[0],1))))\n",
      "\n",
      "    mean1 = [6, 7]\n",
      "    cov1 = [[1, 0.5], [0.5, 1]]\n",
      "    data1 = np.random.multivariate_normal(mean1, cov1, n)\n",
      "    data1 = np.hstack((data1, np.ones((data1.shape[0],1)) * 2))\n",
      "\n",
      "    mean2 = [11, 12]\n",
      "    cov2 = [[1, 0.5], [0.5, 1]]\n",
      "    data2 = np.random.multivariate_normal(mean2, cov2, n)\n",
      "    data2 = np.hstack((data2, np.ones((data2.shape[0],1)) * 3))\n",
      "\n",
      "    data = np.vstack((data0, data1, data2))\n",
      "    np.random.shuffle(data)\n",
      "    print (data.shape)\n",
      "    return data\n",
      "\n",
      "data=generate_data(10)[:,0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(30, 3)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([[ 10.6965,  10.7582],\n",
        "       [ -1.596 ,   0.1623],\n",
        "       [  3.778 ,   5.7559],\n",
        "       [  0.826 ,   1.3241],\n",
        "       [ 10.4596,  10.5911],\n",
        "       [ -0.5951,  -0.0921],\n",
        "       [  3.9859,   5.1566],\n",
        "       [ 10.3765,  12.4163],\n",
        "       [ 11.0378,  11.8638],\n",
        "       [  5.0991,   5.5577],\n",
        "       [ 10.6312,   9.7673],\n",
        "       [ 11.4467,  12.8302],\n",
        "       [  0.1775,   1.9788],\n",
        "       [  0.1471,   1.5177],\n",
        "       [ -0.713 ,   0.665 ],\n",
        "       [ 10.4007,  11.6768],\n",
        "       [ -0.7877,   0.576 ],\n",
        "       [  7.6976,   8.3106],\n",
        "       [  5.5535,   6.3084],\n",
        "       [  3.3058,   5.3871],\n",
        "       [ -0.1272,  -0.9508],\n",
        "       [  7.1259,   9.1257],\n",
        "       [  5.4783,   6.9931],\n",
        "       [  1.4316,   0.5243],\n",
        "       [ 10.3248,  10.7913],\n",
        "       [  7.4118,   9.0393],\n",
        "       [ 10.6222,  12.2063],\n",
        "       [  6.0176,   6.6088],\n",
        "       [  8.7928,  11.942 ],\n",
        "       [  0.9169,   1.7267]])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(123)\n",
      "def minimum_distance(p, centers):\n",
      "    \"\"\"Return the distance to the closest cluster center\"\"\"\n",
      "    min_dist = sys.float_info.max\n",
      "    for i, cc in enumerate(centers):\n",
      "        d = np.sum((p - cc) ** 2)\n",
      "        if min_dist > d:\n",
      "            min_dist = d \n",
      "    return min_dist\n",
      "\n",
      "def kmeanspp(data, k):\n",
      "    \"\"\"Implement the K-means++ algorithm and return k initial cluster centers\"\"\"\n",
      "    #Sample a point uniformly ar random from the data\n",
      "    centers = data[np.random.choice(range(data.shape[0]),1), :]\n",
      "\n",
      "    #Iterate k-1 times through the dataset to select the initial cluster centers\n",
      "    while centers.shape[0] < k:\n",
      "        min_dist = np.zeros(data.shape[0])\n",
      "        for i,p in enumerate(data):\n",
      "            min_dist[i] = minimum_distance(p,centers)\n",
      "        #Calculate cost of the data\n",
      "        phi = np.sum(min_dist)\n",
      "        #Calculate the probability distribution\n",
      "        prob = min_dist/phi\n",
      "        #Select the next centroid using the probability distribution calculated\n",
      "        centers = np.vstack([centers, data[np.random.choice(range(data.shape[0]),1, p = prob), :]])\n",
      "    return centers\n",
      "kmeanspp(data, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "array([[  0.1471,   1.5177],\n",
        "       [ 11.0378,  11.8638],\n",
        "       [  5.0991,   5.5577]])"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Scalable K-means++ Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scalablekmeanspp(data,k,l):\n",
      "    #Sample a point uniformly at random from the data\n",
      "    centers = data[np.random.choice(range(data.shape[0]),1), :]\n",
      "    data2 = data[:, np.newaxis, :]\n",
      "    min_dist = np.zeros(data.shape[0])\n",
      "    for i,p in enumerate(data):\n",
      "        min_dist[i] = minimum_distance(p,centers)\n",
      "    phi = np.sum(min_dist)\n",
      "    \n",
      "    for i in range(round(np.log(phi))):\n",
      "        d2 = (data2 - centers) ** 2\n",
      "        distance = np.sum(d2, axis=2)\n",
      "        min_index = np.zeros(distance.shape)\n",
      "        min_index[range(distance.shape[0]), np.argmin(distance, axis=1)] = 1\n",
      "        min_dist=distance[min_index == True]\n",
      "        phi = np.sum(min_dist)\n",
      "        for j,p in enumerate(data):\n",
      "            prob = l*min_dist[j]/phi\n",
      "            u=np.random.uniform(0,1)\n",
      "            if prob >= u:\n",
      "                centers = np.vstack([centroids, p])\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initial_centroids(data,k,l,r):\n",
      "        # pick the initial centroid randomly\n",
      "        centroids = data[np.random.choice(range(data.shape[0]),1), :]\n",
      "        data_ex = data[:, np.newaxis, :]\n",
      "\n",
      "        passes = 0\n",
      "        while passes < r:\n",
      "            euclidean_dist = (data_ex - centroids) ** 2\n",
      "            distance_arr = np.sum(euclidean_dist, axis=2)\n",
      "            # find the minimum distance, this will be the weight\n",
      "            min = np.min(distance_arr, axis=1).reshape(-1, 1)\n",
      "            # let's use weighted reservoir sampling algorithm to select l centroids\n",
      "            random_numbers = np.random.rand(min.shape[0], min.shape[1])\n",
      "            # replace zeros in min if available with the lowest positive float in Python\n",
      "            min[np.where(min==0)] = np.nextafter(0,1)\n",
      "            # take the n^th root of random numbers where n is the weights\n",
      "            with np.errstate(all='ignore'):\n",
      "                random_numbers = random_numbers ** (1.0/min)\n",
      "            # pick the highest l\n",
      "            cent = data[np.argsort(random_numbers, axis=0)[:, 0]][::-1][:l, :]\n",
      "            # combine the new set of centroids with the previous set\n",
      "            centroids = np.vstack((centroids, cent))\n",
      "            passes += 1\n",
      "        # now we have the initial set of centroids which is higher than k.\n",
      "        # we should reduce this to k using scalable K-Means++\n",
      "        euclidean_dist = (data_ex - centroids) ** 2\n",
      "        distance_arr = np.sum(euclidean_dist, axis=2)\n",
      "        min_location = np.zeros(distance_arr.shape)\n",
      "        min_location[range(distance_arr.shape[0]), np.argmin(distance_arr, axis=1)] = 1\n",
      "        weights = np.array([np.count_nonzero(min_location[:, col]) for col in range(centroids.shape[0])]).reshape(-1,1)\n",
      "        # cluster these r*l + 1 points with K-Means++ to get K points\n",
      "        kmeans_pp = KMeansPP(weights, k)\n",
      "        _, _, _, min_locations = kmeans_pp.cluster()\n",
      "        # calculates the new centroids\n",
      "        new_centroids = np.empty((k, data.shape[1]))\n",
      "        for col in range(0, k):\n",
      "            new_centroids[col] = np.mean(centroids[min_locations[:, col] == True, :], axis=0)\n",
      "        return new_centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}