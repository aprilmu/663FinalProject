{
 "metadata": {
  "name": "",
  "signature": "sha256:d0f67f10ee00965101798d39b246f8f83183bef21728d53fcc300a61b6e74952"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _initial_centroids(data,k,l,r):\n",
      "    #Pick the initial centroid randomly\n",
      "    centroids=data[np.random.choice(range(data.shape[0]),1), :]\n",
      "    data_ex=data[:, np.newaxis, :]\n",
      "\n",
      "    passes = 0\n",
      "    while passes < r:\n",
      "        euclidean_dist = (data_ex-centroids)**2\n",
      "        distance_arr=np.sum(euclidean_dist, axis=2)\n",
      "        #Find the minimum distance, this will be the weight\n",
      "        minimum=np.min(distance_arr, axis=1).reshape(-1, 1)\n",
      "        #Use weighted sampling algorithm to select l centroids\n",
      "        random_numbers=np.random.rand(minimum.shape[0], minimum.shape[1])\n",
      "        #Replace zeros in minimum if available with the lowest positive float in Python\n",
      "        minimum[np.where(minimum==0)]=np.nextafter(0,1)\n",
      "        #Take the n^th root of random numbers where n is the weights\n",
      "        with np.errstate(all='ignore'):\n",
      "            random_numbers = random_numbers**(1.0/minimum)\n",
      "        #Pick the highest l\n",
      "        cent=data[np.argsort(random_numbers, axis=0)[:, 0]][::-1][:l, :]\n",
      "       #Combine the new set of centroids with the previous set            \n",
      "        centroids=np.vstack((centroids, cent))\n",
      "        passes += 1\n",
      "    #Now we have the initial set of centroids which is higher than k.\n",
      "    #We should reduce this to k using scalable K-Means++\n",
      "    euclidean_dist = (data_ex - centroids) ** 2\n",
      "    distance_arr = np.sum(euclidean_dist, axis=2)\n",
      "    min_location = np.zeros(distance_arr.shape)\n",
      "    min_location[range(distance_arr.shape[0]), np.argmin(distance_arr, axis=1)] = 1\n",
      "    weights=np.array([np.count_nonzero(min_location[:, col]) for col in range(centroids.shape[0])]).reshape(-1,1)\n",
      "    #Cluster these r*l + 1 points with K-Means++ to get K points\n",
      "    a, b, c, min_locations = KMeansPP(weights, k)\n",
      "    #Calculates the new centroids\n",
      "    new_centroids = np.empty((k, data.shape[1]))\n",
      "    for col in range(0, k):\n",
      "        new_centroids[col] = np.mean(centroids[min_locations[:, col] == True, :], axis=0)\n",
      "    return new_centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}